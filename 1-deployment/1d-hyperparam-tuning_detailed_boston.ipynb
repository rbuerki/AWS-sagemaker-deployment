{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Boston Housing Prices\n",
    "\n",
    "## Using XGBoost in SageMaker (Hyperparameter Tuning, _detailed approach_)\n",
    "\n",
    "_Deep Learning Nanodegree Program | Deployment_\n",
    "\n",
    "---\n",
    "\n",
    "As an introduction to using SageMaker's High Level Python API for **hyperparameter tuning**, we will look again at the [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) project from before. \n",
    "\n",
    "## General Outline\n",
    "\n",
    "The same steps 1 to 5 are performed but with hyperparameter tuning in step 4 using the _detailed approach_: \n",
    "\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model **with hyperparameter tuning**\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "\n",
    "\n",
    "### On Hyperparameter tuning with the detailed approach\n",
    "\n",
    "This looks a lot like the low-level approach, but Creating a hyperparameter tuning job using the low level approach requires us to describe two different things:\n",
    "\n",
    "- The first, is a training job that will be used as the **base job** for the hyperparameter tuning task. This training job description is almost exactly the same as the standard training job description except that instead of specifying HyperParameters we specify **StaticHyperParameters**. That is, the hyperparameters that we do **not** want to change in the various iterations.\n",
    "- The second thing we need to describe is the **tuning job** itself. This description includes the different ranges of hyperparameters that we do want SageMaker to vary, in addition to the total number of jobs we want to have created and how to determine which model is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "from time import strftime, gmtime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we package up the input data and the target variable (the median value) as pandas dataframes. This\n",
    "# will make saving the data to a file a little easier later on.\n",
    "\n",
    "X_bos_pd = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "Y_bos_pd = pd.DataFrame(boston.target)\n",
    "\n",
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X_bos_pd, Y_bos_pd, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Uploading the data files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our local data directory. We need to make sure that it exists.\n",
    "data_dir = '../data/boston'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'boston-xgboost-tuning-LL'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train and construct the XGBoost model\n",
    "\n",
    "Now that we have the training and validation data uploaded to S3, we can construct our XGBoost model and train it. Unlike in the previous notebooks, instead of training a single model, we will use SageMakers hyperparameter tuning functionality to train multiple models and use the one that performs the best on the validation set.\n",
    "\n",
    "### Set up the training job\n",
    "\n",
    "First, we will set up a training job for our model. This is very similar to the way in which we constructed the training job in previous notebooks. Essentially this describes the *base* training job from which SageMaker will create refinements by changing some hyperparameters during the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='0.90-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-1').\n"
     ]
    }
   ],
   "source": [
    "# We will need to know the name of the container that we want to use for training. SageMaker provides\n",
    "# a nice utility method to construct this for us.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "# We now specify the parameters we wish to use for our training job\n",
    "training_params = {}\n",
    "\n",
    "# We need to specify the permissions that this training job will have. For our purposes we can use\n",
    "# the same permissions that our current SageMaker session has.\n",
    "training_params['RoleArn'] = role\n",
    "\n",
    "# Here we describe the algorithm we wish to use. The most important part is the container which\n",
    "# contains the training code.\n",
    "training_params['AlgorithmSpecification'] = {\n",
    "    \"TrainingImage\": container,\n",
    "    \"TrainingInputMode\": \"File\"\n",
    "}\n",
    "\n",
    "# We also need to say where we would like the resulting model artifacts stored.\n",
    "training_params['OutputDataConfig'] = {\n",
    "    \"S3OutputPath\": \"s3://\" + session.default_bucket() + \"/\" + prefix + \"/output\"\n",
    "}\n",
    "\n",
    "# We also need to set some parameters for the training job itself. Namely we need to describe what sort of\n",
    "# compute instance we wish to use along with a stopping condition to handle the case that there is\n",
    "# some sort of error and the training script doesn't terminate.\n",
    "training_params['ResourceConfig'] = {\n",
    "    \"InstanceCount\": 1,\n",
    "    \"InstanceType\": \"ml.m4.xlarge\",\n",
    "    \"VolumeSizeInGB\": 5\n",
    "}\n",
    "    \n",
    "training_params['StoppingCondition'] = {\n",
    "    \"MaxRuntimeInSeconds\": 86400\n",
    "}\n",
    "\n",
    "# Next we set the algorithm specific hyperparameters. In this case, since we are setting up\n",
    "# a training job which will serve as the base training job for the eventual hyperparameter\n",
    "# tuning job, we only specify the _static_ hyperparameters. That is, the hyperparameters that\n",
    "# we do _not_ want SageMaker to change.\n",
    "training_params['StaticHyperParameters'] = {\n",
    "    \"gamma\": \"4\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"early_stopping_rounds\": \"10\",\n",
    "    \"num_round\": \"200\"\n",
    "}\n",
    "\n",
    "# Now we need to tell SageMaker where the data should be retrieved from.\n",
    "training_params['InputDataConfig'] = [\n",
    "    {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": train_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    },\n",
    "    {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": val_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the tuning job\n",
    "\n",
    "Now that the *base* training job has been set up, we can describe the tuning job that we would like SageMaker to perform. In particular, like in the high level notebook, we will specify which hyperparameters we wish SageMaker to change and what range of values they may take on.\n",
    "\n",
    "In addition, we specify the *number* of models to construct (`max_jobs`) and the number of those that can be trained in parallel (`max_parallel_jobs`). In the cell below we have chosen to train `20` models, of which we ask that SageMaker train `3` at a time in parallel. Note that this results in a total of `20` training jobs being executed which can take some time, in this case almost a half hour. With more complicated models this can take even longer so be aware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to construct a dictionary which specifies the tuning job we want SageMaker to perform\n",
    "tuning_job_config = {\n",
    "    # First we specify which hyperparameters we want SageMaker to be able to vary,\n",
    "    # and we specify the type and range of the hyperparameters.\n",
    "    \"ParameterRanges\": {\n",
    "    \"CategoricalParameterRanges\": [],\n",
    "    \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "            \"MaxValue\": \"0.5\",\n",
    "            \"MinValue\": \"0.05\",\n",
    "            \"Name\": \"eta\"\n",
    "        },\n",
    "    ],\n",
    "    \"IntegerParameterRanges\": [\n",
    "        {\n",
    "            \"MaxValue\": \"12\",\n",
    "            \"MinValue\": \"3\",\n",
    "            \"Name\": \"max_depth\"\n",
    "        },\n",
    "        {\n",
    "            \"MaxValue\": \"8\",\n",
    "            \"MinValue\": \"2\",\n",
    "            \"Name\": \"min_child_weight\"\n",
    "        }\n",
    "    ]},\n",
    "    # We also need to specify how many models should be fit and how many can be fit in parallel\n",
    "    \"ResourceLimits\": {\n",
    "        \"MaxNumberOfTrainingJobs\": 3,  # 20 originally, reduced only for demo \n",
    "        \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    # Here we specify how SageMaker should update the hyperparameters as new models are fit\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    # And lastly we need to specify how we'd like to determine which models are better or worse\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "        \"MetricName\": \"validation:rmse\",\n",
    "        \"Type\": \"Minimize\"\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the tuning job\n",
    "\n",
    "Now that we've built the data structures that describe the tuning job we want SageMaker to execute, it is time to actually start the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobArn': 'arn:aws:sagemaker:eu-west-1:873674308518:hyper-parameter-tuning-job/tuning-job2019-12-25-21-38-19',\n",
       " 'ResponseMetadata': {'RequestId': '8fef7167-c71e-4843-9e72-8cd8b1c14eea',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8fef7167-c71e-4843-9e72-8cd8b1c14eea',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '130',\n",
       "   'date': 'Wed, 25 Dec 2019 21:38:19 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we need to choose a name for the job. This is useful for if we want to recall information about our\n",
    "# tuning job at a later date. Note that SageMaker requires a tuning job name and that the name needs to\n",
    "# be unique, which we accomplish by appending the current timestamp.\n",
    "tuning_job_name = \"tuning-job\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# And now we ask SageMaker to create (and execute) the training job\n",
    "session.sagemaker_client.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n",
    "                                                           HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                                           TrainingJobDefinition = training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning job has now been created by SageMaker and is currently running. Since we need the output of the tuning job, we may wish to wait until it has finished. We can do so by asking SageMaker to output the logs generated by the tuning job and continue doing so until the job terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobName': 'tuning-job2019-12-25-21-38-19',\n",
       " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:eu-west-1:873674308518:hyper-parameter-tuning-job/tuning-job2019-12-25-21-38-19',\n",
       " 'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "  'HyperParameterTuningJobObjective': {'Type': 'Minimize',\n",
       "   'MetricName': 'validation:rmse'},\n",
       "  'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "   'MaxParallelTrainingJobs': 3},\n",
       "  'ParameterRanges': {'IntegerParameterRanges': [{'Name': 'max_depth',\n",
       "     'MinValue': '3',\n",
       "     'MaxValue': '12',\n",
       "     'ScalingType': 'Auto'},\n",
       "    {'Name': 'min_child_weight',\n",
       "     'MinValue': '2',\n",
       "     'MaxValue': '8',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'ContinuousParameterRanges': [{'Name': 'eta',\n",
       "     'MinValue': '0.05',\n",
       "     'MaxValue': '0.5',\n",
       "     'ScalingType': 'Auto'}],\n",
       "   'CategoricalParameterRanges': []}},\n",
       " 'TrainingJobDefinition': {'StaticHyperParameters': {'_tuning_objective_metric': 'validation:rmse',\n",
       "   'early_stopping_rounds': '10',\n",
       "   'gamma': '4',\n",
       "   'num_round': '200',\n",
       "   'objective': 'reg:linear',\n",
       "   'subsample': '0.8'},\n",
       "  'AlgorithmSpecification': {'TrainingImage': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:1',\n",
       "   'TrainingInputMode': 'File',\n",
       "   'MetricDefinitions': [{'Name': 'train:mae',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:auc',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:merror',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-merror:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:auc',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:mae',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:error',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:merror',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-merror:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:logloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:rmse',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:logloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:mlogloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mlogloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:rmse',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:ndcg',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:error',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:mlogloss',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mlogloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:ndcg',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'train:map',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011train-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'validation:map',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "    {'Name': 'ObjectiveMetric',\n",
       "     'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'}]},\n",
       "  'RoleArn': 'arn:aws:iam::873674308518:role/service-role/AmazonSageMaker-ExecutionRole-20191219T211714',\n",
       "  'InputDataConfig': [{'ChannelName': 'train',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-eu-west-1-873674308518/boston-xgboost-tuning-LL/train.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'csv',\n",
       "    'CompressionType': 'None'},\n",
       "   {'ChannelName': 'validation',\n",
       "    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "      'S3Uri': 's3://sagemaker-eu-west-1-873674308518/boston-xgboost-tuning-LL/validation.csv',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}},\n",
       "    'ContentType': 'csv',\n",
       "    'CompressionType': 'None'}],\n",
       "  'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-eu-west-1-873674308518/boston-xgboost-tuning-LL/output'},\n",
       "  'ResourceConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "   'InstanceCount': 1,\n",
       "   'VolumeSizeInGB': 5},\n",
       "  'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "  'EnableNetworkIsolation': False,\n",
       "  'EnableInterContainerTrafficEncryption': False,\n",
       "  'EnableManagedSpotTraining': False},\n",
       " 'HyperParameterTuningJobStatus': 'Completed',\n",
       " 'CreationTime': datetime.datetime(2019, 12, 25, 21, 38, 19, 652000, tzinfo=tzlocal()),\n",
       " 'HyperParameterTuningEndTime': datetime.datetime(2019, 12, 25, 21, 42, 10, 313000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2019, 12, 25, 21, 42, 10, 313000, tzinfo=tzlocal()),\n",
       " 'TrainingJobStatusCounters': {'Completed': 3,\n",
       "  'InProgress': 0,\n",
       "  'RetryableError': 0,\n",
       "  'NonRetryableError': 0,\n",
       "  'Stopped': 0},\n",
       " 'ObjectiveStatusCounters': {'Succeeded': 3, 'Pending': 0, 'Failed': 0},\n",
       " 'BestTrainingJob': {'TrainingJobName': 'tuning-job2019-12-25-21-38-19-001-37430317',\n",
       "  'TrainingJobArn': 'arn:aws:sagemaker:eu-west-1:873674308518:training-job/tuning-job2019-12-25-21-38-19-001-37430317',\n",
       "  'CreationTime': datetime.datetime(2019, 12, 25, 21, 38, 26, tzinfo=tzlocal()),\n",
       "  'TrainingStartTime': datetime.datetime(2019, 12, 25, 21, 40, 35, tzinfo=tzlocal()),\n",
       "  'TrainingEndTime': datetime.datetime(2019, 12, 25, 21, 41, 35, tzinfo=tzlocal()),\n",
       "  'TrainingJobStatus': 'Completed',\n",
       "  'TunedHyperParameters': {'eta': '0.1437539994578057',\n",
       "   'max_depth': '5',\n",
       "   'min_child_weight': '8'},\n",
       "  'FinalHyperParameterTuningJobObjectiveMetric': {'MetricName': 'validation:rmse',\n",
       "   'Value': 3.7090001106262207},\n",
       "  'ObjectiveStatus': 'Succeeded'},\n",
       " 'ResponseMetadata': {'RequestId': '81729c18-2d6e-43db-b4f2-3b2c828776a6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '81729c18-2d6e-43db-b4f2-3b2c828776a6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '5265',\n",
       "   'date': 'Wed, 25 Dec 2019 21:42:12 GMT',\n",
       "   'connection': 'close'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.wait_for_tuning_job(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We can see a lot of details and also monitor the actual progress through log info in the Sagemaker console under 'hyperparameter tuning jobs'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "Now that the tuning job has finished, SageMaker has fit a number of models, the results of which are stored in a data structure which we can access using the name of the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_info = session.sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the pieces of information included in the `tuning_job_info` object is the name of the training job which performed best out of all of the models that SageMaker fit to our data. Using this training job name we can get access to the resulting model artifacts, from which we can construct a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by asking SageMaker to describe for us the results of the best training job. The data\n",
    "# structure returned contains a lot more information than we currently need, try checking it out\n",
    "# yourself in more detail.\n",
    "best_training_job_name = tuning_job_info['BestTrainingJob']['TrainingJobName']\n",
    "training_job_info = session.sagemaker_client.describe_training_job(TrainingJobName=best_training_job_name)\n",
    "\n",
    "model_artifacts = training_job_info['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like when we created a training job, the model name must be unique\n",
    "model_name = best_training_job_name + \"-model\"\n",
    "\n",
    "# We also need to tell SageMaker which container should be used for inference and where it should\n",
    "# retrieve the model artifacts from. In our case, the xgboost container that we used for training\n",
    "# can also be used for inference.\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_artifacts\n",
    "}\n",
    "\n",
    "# And lastly we construct the SageMaker model\n",
    "model_info = session.sagemaker_client.create_model(\n",
    "                                ModelName = model_name,\n",
    "                                ExecutionRoleArn = role,\n",
    "                                PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like in each of the previous steps, we need to make sure to name our job and the name should be unique.\n",
    "transform_job_name = 'boston-xgboost-batch-transform-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# Now we construct the data structure which will describe the batch transform job.\n",
    "transform_request = \\\n",
    "{\n",
    "    \"TransformJobName\": transform_job_name,\n",
    "    \n",
    "    # This is the name of the model that we created earlier.\n",
    "    \"ModelName\": model_name,\n",
    "    \n",
    "    # This describes how many compute instances should be used at once. If you happen to be doing a very large\n",
    "    # batch transform job it may be worth running multiple compute instances at once.\n",
    "    \"MaxConcurrentTransforms\": 1,\n",
    "    \n",
    "    # This says how big each individual request sent to the model should be, at most. One of the things that\n",
    "    # SageMaker does in the background is to split our data up into chunks so that each chunks stays under\n",
    "    # this size limit.\n",
    "    \"MaxPayloadInMB\": 6,\n",
    "    \n",
    "    # Sometimes we may want to send only a single sample to our endpoint at a time, however in this case each of\n",
    "    # the chunks that we send should contain multiple samples of our input data.\n",
    "    \"BatchStrategy\": \"MultiRecord\",\n",
    "    \n",
    "    # This next object describes where the output data should be stored. Some of the more advanced options which\n",
    "    # we don't cover here also describe how SageMaker should collect output from various batches.\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}/batch-bransform/\".format(session.default_bucket(),prefix)\n",
    "    },\n",
    "    \n",
    "    # Here we describe our input data. Of course, we need to tell SageMaker where on S3 our input data is stored, in\n",
    "    # addition we need to detail the characteristics of our input data. In particular, since SageMaker may need to\n",
    "    # split our data up into chunks, it needs to know how the individual samples in our data file appear. In our\n",
    "    # case each line is its own sample and so we set the split type to 'line'. We also need to tell SageMaker what\n",
    "    # type of data is being sent, in this case csv, so that it can properly serialize the data.\n",
    "    \"TransformInput\": {\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": test_location,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # And lastly we tell SageMaker what sort of compute instance we would like it to use.\n",
    "    \"TransformResources\": {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InstanceCount\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_response = session.sagemaker_client.create_transform_job(**transform_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................!\n"
     ]
    }
   ],
   "source": [
    "transform_desc = session.wait_for_transform_job(transform_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output = \"s3://{}/{}/batch-bransform/\".format(session.default_bucket(),prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.3 KiB/2.3 KiB (40.5 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-eu-west-1-873674308518/boston-xgboost-tuning-LL/batch-bransform/test.csv.out to ../data/boston/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $transform_output $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Median Price vs Predicted Price')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Median Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Median Price vs Predicted Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $data_dir/*\n",
    "!rmdir $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
